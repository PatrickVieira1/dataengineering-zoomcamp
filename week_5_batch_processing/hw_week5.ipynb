{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/05 14:49:13 WARN Utils: Your hostname, mx resolves to a loopback address: 127.0.0.1; using 192.168.15.13 instead (on interface eth0)\n",
      "23/03/05 14:49:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/05 14:49:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', StringType(), True), StructField('DOLocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-06.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                  (0 + 1) / 1][Stage 5:>                  (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02510|2021-06-25 12:58:46|2021-06-25 13:28:10|          74|         161|      N|                  null|\n",
      "|              B02765|2021-06-12 13:07:29|2021-06-12 13:13:08|         198|         198|      N|                B02765|\n",
      "|              B02510|2021-06-05 15:06:03|2021-06-05 15:13:43|         258|          76|      N|                  null|\n",
      "|              B02879|2021-06-23 11:21:46|2021-06-23 11:32:17|         161|          68|      N|                B02879|\n",
      "|              B02872|2021-06-16 20:58:43|2021-06-16 21:04:34|         144|         211|      N|                B02872|\n",
      "|              B02510|2021-06-12 14:52:17|2021-06-12 15:01:51|          79|         231|      N|                  null|\n",
      "|              B02871|2021-06-18 08:41:58|2021-06-18 08:48:56|         227|         228|      N|                B02871|\n",
      "|              B02872|2021-06-27 22:12:09|2021-06-27 22:34:28|         158|         113|      N|                B02872|\n",
      "|              B02872|2021-06-22 18:50:31|2021-06-22 19:07:36|          61|          80|      N|                B02872|\n",
      "|              B02866|2021-06-24 23:16:06|2021-06-25 00:11:56|          75|         265|      N|                B02866|\n",
      "|              B02510|2021-06-17 10:44:03|2021-06-17 11:30:59|          74|         132|      N|                  null|\n",
      "|              B02866|2021-06-10 16:00:03|2021-06-10 16:35:18|          69|           3|      N|                B02866|\n",
      "|              B02882|2021-06-29 15:39:51|2021-06-29 16:13:08|          61|         228|      N|                B02882|\n",
      "|              B02867|2021-06-30 17:22:52|2021-06-30 17:46:50|          90|         239|      N|                B02867|\n",
      "|              B02865|2021-06-15 22:26:41|2021-06-15 22:48:00|          91|          26|      N|                B02865|\n",
      "|              B02884|2021-06-17 06:12:58|2021-06-17 06:21:31|         258|          63|      N|                B02884|\n",
      "|              B02510|2021-06-07 14:05:43|2021-06-07 14:20:22|         263|         161|      N|                  null|\n",
      "|              B02884|2021-06-12 13:28:03|2021-06-12 13:55:54|         173|          10|      N|                B02884|\n",
      "|              B02682|2021-06-17 22:02:58|2021-06-17 22:24:48|         244|         143|      N|                B02682|\n",
      "|              B02872|2021-06-12 02:42:00|2021-06-12 02:51:15|         237|          68|      N|                B02872|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.parquet('fhvhv_hw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+------------------+--------+----------------------+\n",
      "|summary|dispatching_base_num|      PULocationID|      DOLocationID| SR_Flag|Affiliated_base_number|\n",
      "+-------+--------------------+------------------+------------------+--------+----------------------+\n",
      "|  count|            14961892|          14961892|          14961892|14961892|              10751439|\n",
      "|   mean|                null|137.17778660613243|141.03749793141134|    null|                  null|\n",
      "| stddev|                null| 75.97052669218735| 78.42338911468418|    null|                  null|\n",
      "|    min|              B02395|                 1|                 1|       N|                B00446|\n",
      "|    25%|                null|                72|                74|    null|                  null|\n",
      "|    50%|                null|               138|               141|    null|                  null|\n",
      "|    75%|                null|               210|               216|    null|                  null|\n",
      "|    max|              B03136|               265|               265|       Y|                B03153|\n",
      "+-------+--------------------+------------------+------------------+--------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('homework_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trips_june_15|\n",
      "+-------------+\n",
      "|       452470|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Question 3: How many taxi trips were started on June 15th? *\n",
    "\n",
    "spark.sql('''\n",
    "select\n",
    "    count(*) as trips_june_15\n",
    "from \n",
    "    homework_table\n",
    "where\n",
    "    day(pickup_datetime) = 15             \n",
    "          \n",
    "          \n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-------------------+\n",
      "|trips_longest|    pickup_datetime|   dropoff_datetime|\n",
      "+-------------+-------------------+-------------------+\n",
      "|            3|2021-06-25 13:55:41|2021-06-28 08:48:25|\n",
      "|            1|2021-06-01 20:34:55|2021-06-02 01:50:39|\n",
      "|            1|2021-06-01 21:43:31|2021-06-02 03:38:23|\n",
      "|            1|2021-06-01 22:52:08|2021-06-02 04:49:02|\n",
      "|            1|2021-06-01 22:56:03|2021-06-02 00:03:13|\n",
      "|            1|2021-06-01 21:28:17|2021-06-02 05:09:22|\n",
      "|            1|2021-06-01 21:45:51|2021-06-02 01:00:06|\n",
      "|            1|2021-06-01 22:52:57|2021-06-02 00:04:18|\n",
      "|            1|2021-06-01 22:29:33|2021-06-02 00:16:49|\n",
      "|            1|2021-06-01 22:57:44|2021-06-02 00:04:09|\n",
      "|            1|2021-06-01 22:52:40|2021-06-02 00:13:17|\n",
      "|            1|2021-06-01 22:12:20|2021-06-02 01:19:52|\n",
      "|            1|2021-06-01 22:57:22|2021-06-02 00:07:05|\n",
      "|            1|2021-06-01 22:46:58|2021-06-02 00:34:20|\n",
      "|            1|2021-06-01 22:55:06|2021-06-02 02:08:07|\n",
      "|            1|2021-06-01 22:54:17|2021-06-02 00:00:35|\n",
      "|            1|2021-06-01 22:16:58|2021-06-02 00:10:55|\n",
      "|            1|2021-06-01 22:46:52|2021-06-02 00:07:52|\n",
      "|            1|2021-06-01 22:41:53|2021-06-02 00:23:06|\n",
      "|            1|2021-06-01 22:38:17|2021-06-02 00:00:54|\n",
      "+-------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Question 4: How long is the longest trip in the dataset? \n",
    "\n",
    "spark.sql('''\n",
    "select\n",
    "    datediff(dropoff_datetime, pickup_datetime) as trips_longest,\n",
    "    pickup_datetime,\n",
    "    dropoff_datetime\n",
    "from \n",
    "    homework_table\n",
    "order by\n",
    "    trips_longest\n",
    "    desc                \n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.csv('taxi_zone_lookup.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_zones.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+\n",
      "|freq_pu_location|PULocationID|                Zone|\n",
      "+----------------+------------+--------------------+\n",
      "|          231279|          61| Crown Heights North|\n",
      "|          221244|          79|        East Village|\n",
      "|          188867|         132|         JFK Airport|\n",
      "|          187929|          37|      Bushwick South|\n",
      "|          186780|          76|       East New York|\n",
      "|          164344|         231|TriBeCa/Civic Center|\n",
      "|          161596|         138|   LaGuardia Airport|\n",
      "|          158937|         234|            Union Sq|\n",
      "|          154698|         249|        West Village|\n",
      "|          152493|           7|             Astoria|\n",
      "|          151020|         148|     Lower East Side|\n",
      "|          147673|          68|        East Chelsea|\n",
      "|          146402|          42|Central Harlem North|\n",
      "|          143683|         255|Williamsburg (Nor...|\n",
      "|          143594|         181|          Park Slope|\n",
      "|          141427|         225|  Stuyvesant Heights|\n",
      "|          139611|          48|        Clinton East|\n",
      "|          139431|         246|West Chelsea/Huds...|\n",
      "|          138428|          17|             Bedford|\n",
      "|          137879|         170|         Murray Hill|\n",
      "+----------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Question 6: What is the name of the most frequent pickup location zone?\n",
    "\n",
    "spark.sql('''\n",
    "select\n",
    "    count(*) as freq_pu_location,\n",
    "    hw.PULocationID,\n",
    "    zo.Zone\n",
    "from \n",
    "    homework_table as hw\n",
    "left join\n",
    "    zones zo on hw.PULocationID = zo.LocationID\n",
    "group by\n",
    "    hw.PULocationID,\n",
    "    zo.Zone\n",
    "order by\n",
    "    freq_pu_location\n",
    "    desc             \n",
    "'''\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
